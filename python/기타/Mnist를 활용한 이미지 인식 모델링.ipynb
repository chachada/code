{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전산물리 기말프로젝트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 요약\n",
    "- 이미지 인식을 주제로 기말프로젝트를 진행함\n",
    "- 0~9 숫자 이미지 데이터를 활용해 머신러닝 기법(4개), 딥러닝 기법(1개)을 적용해 총 5가지 모델을 학습시키고 정확도로 결과를 확인함\n",
    "\n",
    "- 1. 데이터 불러오기\n",
    "    - tensorflow module의 mnist 데이터 활용\n",
    "    - 28 X 28 이미지 데이터\n",
    "    - 60,000개의 학습 데이터와 10,000개의 시험 데이터로 이뤄짐\n",
    "    \n",
    "- 2. 데이터 탐색\n",
    "    - 0 ~ 255 값을 가지고 있어 각 값을 255로 나누어 0 ~ 1로 스케일링 하기로 함\n",
    "    - 0~9 숫자 이미지가 고르게 분포함을 확인\n",
    "    \n",
    "- 3. 모형 적합\n",
    "    - 머신러닝\n",
    "            1) RandomForest\n",
    "            2) Kneighbors\n",
    "            3) Multinomial Logistic Regression\n",
    "            4) Support Vector Machine(SVM(\n",
    "    - 딥러닝\n",
    "            1) CNN(Convolutional Neural Network)\n",
    "- 4. 모형 선정\n",
    "    - 10,000개의 시험데이터 예측 결과로 계산한 정확도를 활용해 모형 평가\n",
    "    - 딥러닝 기법인 CNN이 가장 좋은 결과 (99.46%)\n",
    "    - 머신러닝 중에서는 SVM이 가장 좋은 결과 (97.92%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 인식\n",
    "활용 데이터 : MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train : (60000, 28, 28), y_train : (60000,)\n",
      "x_test : (10000, 28, 28), y_test : (10000,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 shape 확인\n",
    "print(f'x_train : {x_train.shape}, y_train : {y_train.shape}')\n",
    "print(f'x_test : {x_test.shape}, y_test : {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABO0AAACxCAYAAACY2EmBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deZxU1Zn/8e8jAiqCS1gERZgobkl+okGJSxRxJyqokwlGjbtGBfE3ECWKI2MYgxhjxC1iVBAXZIyKUScGmaA4OMoiCq6YBNxAmiCiYkDxzB9dat97LlZRdevUvdWf9+vVLzkPp2491X6tqj5Wn2POOQEAAAAAAADIjo1q3QAAAAAAAACAKBbtAAAAAAAAgIxh0Q4AAAAAAADIGBbtAAAAAAAAgIxh0Q4AAAAAAADIGBbtAAAAAAAAgIxh0S6BmS0ys0NKnOvMbMcy76fs26K+kDmERN4QGplDaGQOoZE5hETeEBqZqx0W7XLKzKab2T/M7KPC12u17gn1zcy2NrMHzexjM1tsZj+udU+of2bWo/Bcd1ete0F9M7NBZjbbzNaY2fha94P6Z2a7mtl/m9kHZvaGmR1b655Qv8ystZndVngP96GZPW9mR9a6L9QvXlcRmpndZWZLzGyVmb1uZmfWuqc0sGiXb4Occ5sXvnaudTOoezdKWiupk6QTJd1sZt+qbUtoBm6UNKvWTaBZeFfSKEm317oR1D8z21jSFEmPSNpa0tmS7jKznWraGOrZxpLeknSgpC0kXSZpspl1r2FPqG+8riK0X0rq7pxrJ+kYSaPM7Ls17qliLNoVYWZ7m9kzZraysGp7g5m1ik3rZ2Z/NbPlZna1mW3U5Panm9krZva+mT1uZt0CPwTkTBYzZ2ZtJB0v6TLn3EfOuaclPSzp5EqvjdrKYt6aXHugpJWSpqV1TdReVjPnnHvAOfeQpL+ncT1kR0Yzt4ukLpKudc6tc879t6T/Ea+rdSGLmXPOfeycG+mcW+Sc+9w594ikv0nK/Q+0zV0W8ybxulrPMpy5l5xza74YFr52SOPatcSiXXHrJP1/Se0l7SPpYEnnxeYcK6mXpD0l9Zd0uiSZ2QBJl0g6TlIHSTMk3VvKnZrZcDN7pMi0Xxb+I/gfM+tT0qNBHmQxcztJWuece71J7QVJfNIu/7KYN5lZO0lXSBq6AY8F+ZDJzKGuZTFztp7at0u5NjIvi5mLz+2kxvd3L5UyH5mW+byh7mQ2c2Z2k5mtlvSqpCWSHivtIWWYc46v2JekRZIOWc/fXSjpwSZjJ+mIJuPzJE0r/Pm/JJ3R5O82krRaUrcmt92xzB57S2orqbWkUyR9KGmHWn/v+KrPzEn6vqSlsdpZkqbX+nvHV/3lrXDb6yRdXPjzSEl31fr7xlf5X3nIXJNrjpI0vtbfM74q+8p65iS1lPRXSRcV/nyYGregeLzW3zu+6jNzsX5aSnpC0i21/r7xVfa/wzzljdfVOvjKWeZaSNpf0ghJLWv9vav0i0/aFWFmO5nZI2a21MxWSbpSjSvKTb3V5M+L1fjrDpLUTdJ1hY+NrpS0Qo3/F3XbSvtyzj3rnPvQObfGOTdBjb9S0a/S66L2Mpq5jyS1i9XaqXGxGDmWxbyZWU9Jh0i6tpLrIJuymDnUtyxmzjn3qaQBkn4gaakaP1U8WdLblVwX2ZDFzDXpbSNJE9W4SDwojWuitrKcN9SnrGfONW478bSk7SSdm9Z1a4VFu+JuVuNHK3u4xg0NL5H/Kw1dm/x5ezVuuik1BvUc59yWTb42dc7NrEKfLqEv5FMWM/e6pI3NrEeT2u7iVyrqQRbz1kdSd0lvmtlSScMkHW9mcyu8LrIhi5lDfctk5pxzLzrnDnTOfcM5d7ikb0p6rtLrIhMymTkzM0m3qfFQseMLi8fIv0zmDXUtL5nbWOxp1yy0lbRK0kdmtouSV2p/ZmZbmVlXSUMk3Veo/1bSz61wwqaZbWFmP6y0ITPb0swON7NNzGxjMztR0gGSHq/02siEzGXOOfexpAckXWFmbcxsPzXuTTCx0muj5jKXN0nj1PgC27Pw9VtJj0o6PIVro/aymDkVXk83UeOvVLT44jU2jWuj5rKauf9XyNlmZjZMUmdJ49O4Nmouk5lT4w/au0o62jn3SUrXRO1lMm+8rta1zGXOzDqa2UAz29zMWpjZ4ZJOkPTflV671li0K26YpB+r8dcAb9VXYWtqiqQ5kuap8QfL2yTJOfegpKskTSp8bHSBpCNLuVMzu8TM/ms9f91SjXsDNEhaLmmwpAHOuddKfEzItixmTmrci2BTScvUuFnouc45PmmXf5nLm3NutXNu6Rdfavz17H845xo26JEhqzKXuYIRkj6RNFzSSYU/jyjl2si8rGbuZDVukr1MjZt4H+q+OvUO+Za5zFnj6YznqPF/hi01s48KXyduyANDJmUubwW8rtavLGbOqXHx8G1J70v6laQLnXNTSnxMmWWucaM+AAAAAAAAABnBJ+0AAAAAAACAjGHRDgAAAAAAAMgYFu0AAAAAAACAjGHRDgAAAAAAAMiYio5cNrMjJF2nxmOcf+ecG/1189u3b++6d+9eyV2iTsyZM2e5c67Dht6OzKEcixYt0vLly62c225I5sgbvsBzHEIjcwgp1OuqRObQiPdyCI3XVYS2vsyVvWhnZi0k3SjpUDUeqzvLzB52zr28vtt0795ds2fPLvcuUUfMbHEZtyFzKEuvXr3Kut2GZo684Qs8xyE0MoeQQr2uSmQOjXgvh9B4XUVo68tcJb8eu7ekN5xzf3XOrZU0SVL/Cq4HFEPmEBqZQ0jkDaGROYRG5hAamUNI5A2pq2TRbltJbzUZv12oRZjZ2WY228xmNzQ0VHB3AJlDcEUzR96QIp7jEBqZQ2hkDqHxXg4h8RyH1FWyaJe0p4DzCs6Nc871cs716tBhg38lHGiKzCG0opkjb0gRz3EIjcwhNDKH0Hgvh5B4jkPqKlm0e1tS1ybj7SS9W1k7wNcicwiNzCEk8obQyBxCI3MIjcwhJPKG1FWyaDdLUg8z+yczayVpoKSH02kLSETmEBqZQ0jkDaGROYRG5hAamUNI5A2pK/v0WOfcZ2Y2SNLjajzO+Hbn3EupdQbEkDmERuYQEnlDaGQOoZE5hEbmEBJ5QzWUvWgnSc65xyQ9llIvQFFkDqGROYRE3hAamUNoZA6hkTmERN6Qtkp+PRYAAAAAAABAFbBoBwAAAAAAAGQMi3YAAAAAAABAxrBoBwAAAAAAAGQMi3YAAAAAAABAxrBoBwAAAAAAAGQMi3YAAAAAAABAxrBoBwAAAAAAAGQMi3YAAAAAAABAxrBoBwAAAAAAAGTMxrVuAEB4c+bM8Wo33HCDV5swYUJkfMopp3hzBg8e7NX23HPPCroDAAAAkLYhQ4Z4tbFjx0bG3/72t705jzzyiFfr1q1beo0BWC8+aQcAAAAAAABkDIt2AAAAAAAAQMawaAcAAAAAAABkTEV72pnZIkkfSlon6TPnXK80msqrdevWebUPPvigrGsl7S+2evXqyPi1117z5tx4441ebdiwYZHxvffe683ZZJNNvNrw4cMj48svvzy52YDI3IabN2+eVzvkkEO82qpVq7yamUXGd955pzdnypQpXm3FihUb0mKmkbnsmzZtWmR84oknenOefPJJr7bzzjtXradKkLnaGTVqlFf7t3/7N6/mnIuMp0+f7s058MADU+urmsgbQiNz6fjwww+92kcffeTVHn300ch42bJl3pyhQ4d6tdatW1fQXbY018wtWrTIq02cONGrxd/vv/zyy96cV1991auxp12y5po3SXr99de92tq1a73ajBkzIuPzzjvPmxPPZdoGDBgQGU+aNMmb06pVq6r2UKo0DqI4yDm3PIXrAKUicwiNzCE0MoeQyBtCI3MIjcwhJPKG1PDrsQAAAAAAAEDGVLpo5yT9yczmmNnZSRPM7Gwzm21msxsaGiq8O4DMIbivzRx5QxWQOYTE6ypCI3MIjddVhMRzHFJV6aLdfs65PSUdKel8MzsgPsE5N84518s516tDhw4V3h1A5hDc12aOvKEKyBxC4nUVoZE5hMbrKkLiOQ6pqmhPO+fcu4V/LjOzByXtLempNBoL5c033/RqSZslzpw5MzJ++umnvTkrV670avfff38F3X29rl27erXBgwd7tQcffDAybtu2rTdn991392pZ3ES7HjJXbc8991xkfPzxx3tzkg5ISdrss127dpFx0macy5f72zU888wzkfF3v/tdb05WNvYsplaZe+qp6F38/e9/9+Yce+yx1W4jF2bNmhUZ9+qV7/1+eZ4LZ/z48ZHx6NGjvTktWrTwavGDp6q9WXI1kTeERuaK+9vf/hYZjxkzxpsTf68lSfPnzy/r/pYuXerVxo4dW9a1sqi5Zi5pMSjp57ukQ+VQvnrN24IFC7zahAkTIuP//M//9OZ8/vnnXu2dd96JjJPeR1X7vVU89z/96U+9Ob/5zW+8Wvzn4xDK/qSdmbUxs7Zf/FnSYZL8f5NASsgcQiNzCI3MISTyhtDIHEIjcwiJvKEaKvmkXSdJDxZWQDeWdI9z7o+pdAUkI3MIjcwhNDKHkMgbQiNzCI3MISTyhtSVvWjnnPurJP93KoEqIXMIjcwhNDKHkMgbQiNzCI3MISTyhmqo9CAKAAAAAAAAACmr6CCKPHr++ecj4759+3pzkjbpz4L4ZtijRo3y5rRp08arnXjiiZFxly5dvDlbbbWVV9t55503tEVU0erVq73a3LlzvdpJJ50UGb/77rtl32ePHj0i44suusib86Mf/cir7bfffpFxUlYvueSSsvtqDqZPnx4ZL1y40JvTHA+iSNrMNr5hd9IBQ865qvWE/Fq8eHFkvGbNmhp1gqx49tlnvdrEiRMj4/hBQVLyBt1Jrrnmmsg46T3ZjBkzvNrJJ58cGffu3buk+0O2vPrqq14taaPzu+66KzL+5JNPvDlJr2vbb7+9V4sfQPfyyy97cyZPnuzVzjvvvMh4l1128eYg25J+LuzWrVsNOkE9SPrZ7dFHH61BJ9URP1RDkk4//XSvtv/++4doJ4JP2gEAAAAAAAAZw6IdAAAAAAAAkDEs2gEAAAAAAAAZ0+z2tIv/Hn/79u29OdXc0y5pD5Kk/eT+/Oc/e7VWrVpFxvH9TVDfzjnnHK92zz33VPU+58yZExl/9NFH3pwDDzzQq8X3Y5s/f36qfTUH8X0V9t133xp1ki1LlizxauPGjYuMk54b2YsHTzzxhFcbO3Zs0dslZeeRRx6JjDt16lR+Y6iZ++67z6sNGTLEqzU0NETGSXuJ9enTx6stX77cqw0bNqxoX0nXj19r0qRJRa+DsJJ+frj44osj46TMrVq1qqz722mnnbza448/7tXWrl0bGSc9p8UzLiXnF/mycuVKr/bCCy/UoBPUg0MPPdSrlbKnXceOHb3aGWecERkn7Vm90Ualfb5s5syZkfGTTz5Z0u3yhE/aAQAAAAAAABnDoh0AAAAAAACQMSzaAQAAAAAAABnDoh0AAAAAAACQMc3uIIqtt946Mr766qu9OX/4wx+82h577BEZX3DBBSXdX8+ePSPjpI2w27Rp49UWLFjg1UrZMBv1I34IRHzjcyl5s+q4pM2xjzrqKK+WtDl2ly5dIuP4fwdSaQeplNInopI2ZIV05plnFp3To0ePAJ0gy55++mmvduqpp3q1UjaA/9nPfubV4odaIXs+++wzrzZr1qzI+KyzzvLmfPzxx14tfuDSZZdd5s3Zf//9vdqaNWu82r/8y79ExkkHByTp1atXSfNQOw8++KBXu/XWW1O59o477ujVpk6d6tW6du3q1RYuXJhKD8if1atXe7XFixeXda3486eUfKgJr4/169xzz/VqAwYMKHq7li1berVtttkmlZ4k/73ct7/9bW/OO++8U/Q6SY9lr732Kr+xFPFJOwAAAAAAACBjWLQDAAAAAAAAMoZFOwAAAAAAACBjii7amdntZrbMzBY0qW1tZlPNbGHhn/6mVkCZyBxCI3MIjcwhJPKG0MgcQiNzCIm8IaRSDqIYL+kGSXc2qQ2XNM05N9rMhhfGF6ffXvUlbTjYt29fr9a2bdvI+MUXX/Tm/O53v/Nq8c39kw6dSJK0geK4ceNKum0dGK86zlySefPmebVDDjkkMk7aMN3MvFq/fv0i43vvvdebM336dK/2H//xH14tvul/hw4dvDm777570b4effRRb87cuXO92p577unVAhmvGmYu6fnkvffeq8Zd5d7KlSuLzjn00EMDdFKx8Wpmz3MhTZgwwau9++67RW+XdHDPT37ykzRaqrXxamZ5u+uuu7zaGWecUfR2hx12mFe77777IuN27dqV1EP8dlJpB08kHSZwyimnlHSfGTJezSxzkydPLut23bt392p77713ZHzVVVd5c5JykuTVV18tq68cGq9mlrli4gfKSdJpp53m1S6//PKi10qas+WWW3q1QYMGldhd7o1XM8vbxhv7S0elPg9VU/x19f333y/rOkmPpXXr1mVdK21FP2nnnHtK0opYub+kL94RT5BU/NgQoERkDqGROYRG5hASeUNoZA6hkTmERN4QUrl72nVyzi2RpMI/O65vopmdbWazzWx2Q0NDmXcHkDkEV1LmyBtSROYQEq+rCI3MITReVxESz3GoiqofROGcG+ec6+Wc65X0q3VA2sgcQiJvCI3MITQyh9DIHEIibwiNzGFDlLKnXZL3zKyzc26JmXWWtCzNpmqtlL1Ktthii5KuFd/nbuDAgd6cjTbiEN8S1E3mXn/9da82ZswYr/bBBx9ExklP6J07d/Zq8X1vNt98c2/OUUcdVVItLatXr/Zqv/rVr7zaPffcU7UeyhAsc4899phX++STT6p1d7mRtK/fokWLit5u2223rUI3QdTN81xIy5cv92q33XabV2vRooVXi+/HM2LEiPQay766yVvSv7crr7zSq8X3Wz3//PO9OaNGjfJqpe5hF5e0V2wpxo4d69Xq5Ie6uslckqS9reP7USftmbjjjjt6tY4d1/sBnQ3WzPfIrevMleOyyy7zaqXsaYeSkLcqmzRpkleLP88m/dxZiiuuuKKs24VQ7mrRw5K+WBk4RdKUdNoB1ovMITQyh9DIHEIibwiNzCE0MoeQyBuqouiinZndK+kZSTub2dtmdoak0ZIONbOFkg4tjIFUkDmERuYQGplDSOQNoZE5hEbmEBJ5Q0hFfz3WOXfCev7q4JR7ASSROYRH5hAamUNI5A2hkTmERuYQEnlDSGymBgAAAAAAAGRMuQdRNHsjR470anPmzPFq06dPj4yfeOIJb07SprSoH2vWrImMhw0b5s159NFHvVp84+s777zTm9OrVy+vlpcDDN56661at5AZr732WtE53/rWtwJ0ki1J/60sXbrUq+28886Rcdu2bavWE2ovfhjJcccdV/a1Bg8eHBn37du37GshnPhm0UmHTrRu3dqrHX744ZHxVVdd5c3ZdNNNi97/P/7xD6/2pz/9yastXrzYqznnIuOkTeH79+9ftAdkT5cuXbxa0s8Loc2cObPWLSDj4s9LQGh33XWXVxs92v/t4r/85S9ebe3atWXdZ8+ePSPjli1blnWdEPikHQAAAAAAAJAxLNoBAAAAAAAAGcOiHQAAAAAAAJAxLNoBAAAAAAAAGcNBFGVq06aNV7v11lu92p577hkZn3XWWd6cgw46yKslHTBw/vnnR8ZmVrRP1N7cuXMj46RDJ5JMmTIlMj7wwANT6wn5s9dee9W6hbKtWrXKq/3xj3/0avFNaJM2dk8yYsSIyHjLLbfcgO6QN/HszJ8/v6TbHXzwwV5tyJAhqfSE6lm5cqVXu+mmmyLjpPdD8UMnJOmhhx4qq4c33ngjMj7xxBO9ObNnzy7pWj/84Q8j44suuqisnlDfxo4dGxl//PHH3pykwwOS/ltYsGBB0fvbb7/9vNo+++xT9HaoD/Hc8DMmksQPApOkiRMnRsZJh26WYsaMGV6t3BzGD3OUkg+e6tevX2RcykFUtcIn7QAAAAAAAICMYdEOAAAAAAAAyBgW7QAAAAAAAICMYU+7FO2www5ebfz48ZHxaaed5s258847S6rF97P4yU9+4s3p3LlzsTYR2L/+679Gxkl7kPTp08er5XkPu6THWM4cfGXFihWpXeuFF17wap9//nlkPG3aNG/O22+/7dXWrl0bGd99991Fry0l7xvRu3fvyLh169benE8//dSrJe0BivqQtAfZ8OHDi97u+9//vlebMGGCV9tiiy3KawzBxJ9jJKmhoaHo7eJ7gknSsmXLIuM77rjDmxPfT1aSXnrppcj4ww8/9OYk7b2z0Ub+/xs/6aSTIuOkPZJRP1avXh0Zx7MkSVdccYVXK2X/41L3tIvr0qWLV0v6b6FFixZFrwWgPiXtF3zMMcd4tTfffDNEOxvkgAMO8Gpnn312DTpJD5+0AwAAAAAAADKGRTsAAAAAAAAgY1i0AwAAAAAAADKm6KKdmd1uZsvMbEGT2kgze8fM5hW++lW3TTQnZA6hkTmERN4QGplDaGQOoZE5hETeEFIpB1GMl3SDpPjJCNc6536Vekd15thjj42Md9xxR2/O0KFDvdoTTzzh1X7+859HxosXL/bmXHrppV5t2223LdpnxoxXTjP3yCOPeLV58+ZFxkmbBCdt7Jln8ceY9Jh79uwZqp1SjFcNM5d0KEP8e3bOOed4c6688sqy7i/pIIr4htYtW7b05my22WZebdddd42MTz/9dG/Od7/7Xa+WdPhKp06dIuPtttvOm/PJJ594tV122cWrZdx45fQ5rpoWLVrk1Y477riyrvXNb37Tq8Xz1cyMV04z16pVK6/WsWPHyDh+wIQkde/e3auVskl/kvj7qHbt2nlz3n33Xa/Wvn17r3b00UeX1UMOjVdOM1eKpEORnn/+ea92/PHHR8ZJOUl6bY0fFrHvvvt6c/74xz96tfihdUnWrVvn1R544AGvNmTIkMg46b/FjBmvOs4cMme8yFtqBwumeUDhH/7wB6/22GOPebV+/fKzplr0k3bOuackpXdsIVAEmUNoZA4hkTeERuYQGplDaGQOIZE3hFTJnnaDzOzFwkdDt1rfJDM728xmm9nshoaGCu4OIHMIrmjmyBtSxHMcQiNzCI3MITTeyyEknuOQunIX7W6WtIOknpKWSLpmfROdc+Occ72cc706dOhQ5t0BZA7BlZQ58oaU8ByH0MgcQiNzCI33cgiJ5zhURVmLds6595xz65xzn0u6VdLe6bYFRJE5hEbmEBJ5Q2hkDqGROYRG5hASeUO1lHIQhcfMOjvnlhSGx0pa8HXz8ZXvfOc7Xm3y5MleLWkDxVNPPTUy/u1vf+vNWbhwoVebOnXqBnSYTXnJXNIm+WvXro2M4xtoS9KPfvSjqvWUpjVr1ni1kSNHFr3dwQcf7NVGjx6dRktVEzJzN910k1fr1q1bZDxz5szU7m/77bf3av3794+Md9ttN2/O9773vdR6SDJu3LjIOGlz+aQDBupBXp7jqumqq67yai1atCjrWsOHD6+0nbqXl8xtueWWXu2hhx6KjI866ihvzt///nevFj8MLP68J/nvtSRp6623jowHDhzozUk6YCBpXnOWl8wlib+XSzoEIn74XJKk90wHHXSQV9t///0j4xUr/K2z+vbt69Xmz59ftIek19ak58z4e4UBAwZ4c1q3bl30/mopz5kLqdxDAJ566imvNmjQoErbya16ylvSmsX06dO92sSJEyPjI444wpuzySabpNbXbbfd5tXGjh2b2vWzquiinZndK6mPpPZm9rakyyX1MbOekpykRZL8Yw2BMpE5hEbmEBJ5Q2hkDqGROYRG5hASeUNIRRftnHMnJJT9JU4gJWQOoZE5hETeEBqZQ2hkDqGROYRE3hBSJafHAgAAAAAAAKgCFu0AAAAAAACAjCnrIAqkK2mT5ZNPPtmrnXnmmZHxp59+6s1J2hA0vmlknz59NqxBpCppM87OnTvXoJPi4gdPjBo1ypszZswYr9a1a9fIeOjQod6czTffvMLu6tvFF19c6xaCmzZtWtE5//zP/xygE4Qwb968yPjxxx8v6zrHHHOMV9t5553LuhbyoXfv3pFxQ0NDVe8v/t7qySef9OaYmVer14Nz6l3S++vLL788Mk5675PkyCOPjIwHDx7szUn6OSCe6X79+nlzXnzxRa+WdDDERRddFBknHVYxZcoUr/bjH/84Mj700EOLXluSttpqK68Wt8ceexSdg3Diz19Jz2dJfv/733u1l19+OTJOOtgM+RQ/JE+SRowYEbSHpMN8msNBFHzSDgAAAAAAAMgYFu0AAAAAAACAjGHRDgAAAAAAAMgY9rQLLGn/ifvvv9+rzZo1y6sl7bERl7RvwAEHHFBidwghaf+lLIjvLyX5e7bcd9993pz+/ft7tQceeCC9xoAmBgwYUOsWkJLDDjssMn7//fdLul18P7MJEyak1hOQ5JNPPomMk/Z7SqoNHDiwaj0hHevWrfNql112mVe7+uqrI+OkfXl/+ctferUTTjghMk7avy7pPX9877u5c+d6c3baaSevdvPNN3u1gw46KDJetWqVN2fmzJle7e67746MH374YW9O0j53cdtvv71X+9vf/lb0dgjnpz/9aWR8yy23lH2tcePGRca/+c1vyr4WEFfu/sd5xyftAAAAAAAAgIxh0Q4AAAAAAADIGBbtAAAAAAAAgIxh0Q4AAAAAAADIGA6iSNFrr73m1a6//vrIOGmD/qVLl5Z1fxtv7P/r69y5s1fbaCPWZkNxzhWtPfTQQ96c6667rmo9Jfn1r3/t1X7xi194tQ8++CAyPumkk7w5d955Z3qNAWg2li9fHhm3aNGipNudf/75kXHShvBAmg4//PBat4AqiW+aL/mHTkhSmzZtIuOkjfrjh+tI0v/+7/9GxnfccYc357HHHvNq8cNPLr/8cm/Oaaed5tW6du3q1eLatWvn1Y444oiitXvvvdebEz+sIsm1115bdA5qa9ddd611Cwgo6XDL+AEPBx98sDdn0003rVpPSW6//XavduGFFwbtIStYzaLpbnEAAA21SURBVAEAAAAAAAAyhkU7AAAAAAAAIGNYtAMAAAAAAAAypuiinZl1NbM/m9krZvaSmQ0p1Lc2s6lmtrDwz62q3y6aAzKH0MgcQiJvCI3MITQyh5DIG0IjcwiplIMoPpM01Dk318zaSppjZlMlnSppmnNutJkNlzRc0sXVa7W24odF3HPPPd6cG264wastWrQotR722muvyPjSSy/15hxzzDGp3V8N5TZzZla0lnTwyAUXXODVTj/99Mj4G9/4hjcnvsGxJE2cODEyfuGFF7w5b731llfr1q2bV4tvQnzeeed5c+pEbjPX3CxcuNCr7bPPPjXopCLNLm9JG6bHD+lZt25dSdfad999U+mpmWl2mUtTfINulCQXmbviiitKmvfZZ59FxmPGjPHmjBw50qslvWaV4t///d8j45///OfenFIP70nLCSecUFKtRnKRt6waPHhwZBw/SFGS3njjjZKuFT9cL35tSdphhx02oLvMykXmZsyY4dWuvPJKr/anP/0pMk5awyjloJtSrVixIjJOOpBn6NChXu3jjz8ueu3NNtvMq4U+RCNtRT9p55xb4pybW/jzh5JekbStpP6SJhSmTZA0oFpNonkhcwiNzCEk8obQyBxCI3MIibwhNDKHkDZoTzsz6y5pD0nPSurknFsiNYZWUsf13OZsM5ttZrMbGhoq6xbNDplDaBuaOfKGSvAch9DIHEIjcwiJvCE0ModqK3nRzsw2l/R7SRc651aVejvn3DjnXC/nXK8OHTqU0yOaKTKH0MrJHHlDuXiOQ2hkDqGROYRE3hAamUMIpexpJzNrqcYw3u2ce6BQfs/MOjvnlphZZ0nLqtVkNb333nte7aWXXvJqgwYNioxfffXV1Hro3bu3V7vooou8Wv/+/SPjjTaq38N/6zlz8X1RJOnGG2/0avfff39kvMUWW3hzXn/99bJ6SNoTqm/fvl6t1L1e6kE9Z66efP7557VuIRX1nLd58+Z5talTp3q1+H6frVu39uYk7aPZqVOnCrprvuo5c9X2l7/8pdYt5FIeMrfNNtt4tWXL/JbWrFkTGSftF5zkBz/4QWR8wAEHeHMGDPB/e6579+6Rcej96/IoD3nLi29961tejedBXx4yl7Sn4Pz584veLmnfzrZt26bSk+S/L5wzZ443J2mv+CR9+vSJjJPeOx500EGlN5dBpZwea5Juk/SKc+7XTf7qYUmnFP58iqQp6beH5ojMITQyh5DIG0IjcwiNzCEk8obQyBxCKuWTdvtJOlnSfDP74n+fXyJptKTJZnaGpDcl/bA6LaIZInMIjcwhJPKG0MgcQiNzCIm8ITQyh2CKLto5556WtL7PJh6cbjsAmUN4ZA4hkTeERuYQGplDSOQNoZE5hFS/m6IBAAAAAAAAOVXSQRR5tWLFCq92zjnnRMZJG2anudHmfvvtFxkPHTrUm3P44Yd7tU033TS1HhDOPvvs49X23nvvyPi5554r6VpLly6NjJMOTUnSvn37yHjgwIHenOuuu66kawFZ88wzz3i1U089NXwjWK+VK1d6tVKev7p06eLVrrnmmlR6Airx/e9/PzJ2ztWoE6Ttqaee8moPPfSQV5s7d25k3LFjR2/O6aef7tW22mqryLhVq1Yb2iIQ3Nlnn+3VHn744Rp0glq56aabat1C4vPsMccc49XiP9dusskmVeupVvikHQAAAAAAAJAxLNoBAAAAAAAAGcOiHQAAAAAAAJAxLNoBAAAAAAAAGZPbgyieffbZyHjMmDHenFmzZnm1t99+O5X732yzzbzaBRdc4NUuvfTSyLhNmzap3D+yabvttvNqDzzwQGR8yy23eHN+8YtflHV/Q4YM8WrnnntuZNyjR4+yrg0AAKTvfOc7kXHS62rSIWZJtQ4dOqTXGCrWtm1br3byySeXVAPq1W677VZS7eWXXw7RDipwxx13eLXrr7/eq02YMKFqPey4445eLb6WEj/wSZLOOussrxZ/PW4u+KQdAAAAAAAAkDEs2gEAAAAAAAAZw6IdAAAAAAAAkDG53dPuwQcf/NpxqZJ+P//oo4/2ai1atIiMhw0b5s3Zcssty+oB9a1z586R8ciRI705STWguTnyyCMj48mTJ9eoE1Ril1128Wr77ruvV5sxY0aIdoDUXXLJJV7tjDPOKGneDTfcEBknvQ8FgFrq1q2bV5s/f34NOkGl9thjD6928803e7XevXtHxiNGjPDmrFixwqsNGDAgMj7ssMO8Of379/dq22yzjd8s1otP2gEAAAAAAAAZw6IdAAAAAAAAkDEs2gEAAAAAAAAZU3TRzsy6mtmfzewVM3vJzIYU6iPN7B0zm1f46lf9dtEckDmERN4QGplDaGQOoZE5hETeEBqZQ0ilHETxmaShzrm5ZtZW0hwzm1r4u2udc7+qXnvrN3r06K8dI9cymTnULfKWEaeeeurXjutIXWcuaXPhJ598sgadoIm6zlxoxx13nFebNGmSV5s6dapXix88dccdd3hz2rRpU35z2UHmEBJ5Q2i5zVzr1q292jnnnPO1Y9RW0UU759wSSUsKf/7QzF6RtG21G0PzReYQEnlDaGQOoZE5hEbmEBJ5Q2hkDiFt0J52ZtZd0h6Sni2UBpnZi2Z2u5lttZ7bnG1ms81sdkNDQ0XNovkhcwiJvCE0MofQyBxCI3MIibwhNDKHait50c7MNpf0e0kXOudWSbpZ0g6SeqpxlfmapNs558Y553o553p16NAhhZbRXJA5hETeEBqZQ2hkDqGROYRE3hAamUMIJS3amVlLNYbxbufcA5LknHvPObfOOfe5pFsl7V29NtHckDmERN4QGplDaGQOoZE5hETeEBqZQyhF97QzM5N0m6RXnHO/blLvXPhdbkk6VtKC6rSI5obMISTyhtDIHEIjc+lq166dV5s8ebJXu/TSS73aTTfdFBnHD6aQpN1226385jKCzCEk8obQyBxCKuX02P0knSxpvpnNK9QukXSCmfWU5CQtksQRI0gLmUNI5A2hkTmERuYQGplDSOQNoZE5BFPK6bFPS7KEv3os/XYAMoewyBtCI3MIjcwhNDKHkMgbQiNzCGmDTo8FAAAAAAAAUH2l/HosAAAAgPVI2ufu+uuvL6kGAACwPnzSDgAAAAAAAMgYFu0AAAAAAACAjGHRDgAAAAAAAMgYFu0AAAAAAACAjDHnXLg7M2uQtFhSe0nLg91xuug9Hd2ccx2qfSdkrqay1HfovEnZevwbIq99S9nqnee40tF7Oshc6fLae5b6DpI3qS4yl9e+pWz1znu50uW1bylbvfO6Wjp6T0di5oIu2n15p2aznXO9gt9xCug9n/L82PPae177TkteH39e+5by3Xul8vzY6T2f8vzY89p7XvtOS14ff177lvLdexry+vjz2reU794rlefHTu/Vxa/HAgAAAAAAABnDoh0AAAAAAACQMbVatBtXo/tNA73nU54fe157z2vfacnr489r31K+e69Unh87vedTnh97XnvPa99pyevjz2vfUr57T0NeH39e+5by3Xul8vzY6b2KarKnHQAAAAAAAID149djAQAAAAAAgIxh0Q4AAAAAAADImOCLdmZ2hJm9ZmZvmNnw0Pe/IczsdjNbZmYLmtS2NrOpZraw8M+tatljEjPramZ/NrNXzOwlMxtSqGe+97SRtzDI3FfIXPWRtygyV31kLorMVR+Z+wp5C4PMfYXMVR95iyJz1ZfnzAVdtDOzFpJulHSkpN0knWBmu4XsYQONl3RErDZc0jTnXA9J0wrjrPlM0lDn3K6Svifp/ML3OQ+9p4a8BUXmROYCIm8FZC4YMldA5oIhcyJvgZE5kbmAyFsBmQsmt5kL/Um7vSW94Zz7q3NuraRJkvoH7qFkzrmnJK2IlftLmlD48wRJA4I2VQLn3BLn3NzCnz+U9IqkbZWD3lNG3gIhc18icwGQtwgyFwCZiyBzAZC5L5G3QMjcl8hcAOQtgswFkOfMhV6021bSW03GbxdqedLJObdEavwXL6ljjfv5WmbWXdIekp5VznpPAXmrATJH5kJq5nmTyFxwZI7MhdbMM0feaoDMkbmQmnneJDIXXN4yF3rRzhJqLnAPzYaZbS7p95IudM6tqnU/NUDeAiNzZC4k8iaJzAVF5iSRuaDIHHkLjcyRuZDImyQyF1QeMxd60e5tSV2bjLeT9G7gHir1npl1lqTCP5fVuJ9EZtZSjWG82zn3QKGci95TRN4CInOSyFww5O1LZC4QMvclMhcImZNE3oIic5LIXDDk7UtkLpC8Zi70ot0sST3M7J/MrJWkgZIeDtxDpR6WdErhz6dImlLDXhKZmUm6TdIrzrlfN/mrzPeeMvIWCJn7EpkLgLxFkLkAyFwEmQuAzH2JvAVC5r5E5gIgbxFkLoBcZ845F/RLUj9Jr0v6i6RLQ9//BvZ6r6Qlkj5V4wr4GZK+ocZTRRYW/rl1rftM6Ht/NX6k9kVJ8wpf/fLQexW+F+QtTO9k7qvvBZmrft/kLfr9IHPV75vMRb8fZK76fZO5r74X5C1M72Tuq+8Fmat+3+Qt+v0gc9XvO7eZs8IDAAAAAAAAAJARoX89FgAAAAAAAEARLNoBAAAAAAAAGcOiHQAAAAAAAJAxLNoBAAAAAAAAGcOiHQAAAAAAAJAxLNoBAAAAAAAAGcOiHQAAAAAAAJAx/wfIZvXVk9KYiwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1584x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 훈련데이터 및 라벨 확인\n",
    "def show_grid_images(image_num_list, ncols=8, title=None):\n",
    "    figure, axs = plt.subplots(figsize=(22, 4), nrows=1, ncols=ncols)\n",
    "    for i in range(ncols):\n",
    "        image = x_train[image_num_list[i]]\n",
    "        axs[i].imshow(image, cmap=plt.cm.gray_r, interpolation = \"nearest\")\n",
    "        axs[i].set_title(f'label : {y_train[image_num_list[i]]}')  \n",
    "show_grid_images(np.arange(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_value : 0, max_value : 255\n"
     ]
    }
   ],
   "source": [
    "# 데이터 min/max 확인\n",
    "print(f'min_value : {x_train[0].min()}, max_value : {x_train[0].max()}')\n",
    "\n",
    "# -> 스케일링 필요성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index\n",
       "label       \n",
       "0       5923\n",
       "1       6742\n",
       "2       5958\n",
       "3       6131\n",
       "4       5842\n",
       "5       5421\n",
       "6       5918\n",
       "7       6265\n",
       "8       5851\n",
       "9       5949"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 분포 확인\n",
    "import pandas as pd\n",
    "pd.DataFrame(y_train, columns=['label']).reset_index().groupby('label').count()\n",
    "\n",
    "# -> 라벨 5가 5,421개로 최소 표본 / 라벨 1이 6,742개로 최대 표본을 가지고 있음\n",
    "# -> 라벨 분포가 유사하므로 imbalance 하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모형 적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - 머신러닝\n",
    "1) 28X28 데이터를 784(28X28)로 Flatten해 784개의 feature를 가지고 있는 데이터 셋으로 간주\n",
    "\n",
    "2) 4가지 머신러닝 모델을 적합(randomforest, kneighbors, multinomial logistic regression, svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 28X28 데이터를 784(28X28)로 Flatten해 784개의 feature를 가지고 있는 데이터 셋으로 간주\n",
    "# 데이터 정규화\n",
    "x_train = x_train/255.0\n",
    "\n",
    "# one-hot encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "# x_train flatten\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train : (60000, 784), y_train : (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 shape 확인\n",
    "print(f'x_train : {x_train.shape}, y_train : {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\차정윤\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "# 2) 4가지 머신러닝 모델을 적합\n",
    "import joblib\n",
    "\n",
    "# RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(x_train, y_train)\n",
    "# 모형 저장\n",
    "joblib.dump(rf_model, './rf_model.pkl')\n",
    "rf_model = joblib.load('./rf_model.pkl') \n",
    "\n",
    "\n",
    "# KNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kn_model = KNeighborsClassifier()\n",
    "kn_model.fit(x_train, y_train)\n",
    "# 모형 저장\n",
    "joblib.dump(kn_model, './kn_model.pkl')\n",
    "kn_model = joblib.load('./kn_model.pkl') \n",
    "\n",
    "\n",
    "# 다항로지스틱회귀분석\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression(multi_class = \"multinomial\", solver = \"lbfgs\")\n",
    "# 다항로지스틱은 원핫인코딩 하지 않음\n",
    "lr_model.fit(x_train, np.argmax(y_train, axis=1))\n",
    "# 모형 저장\n",
    "joblib.dump(lr_model, './lr_model.pkl')\n",
    "lr_model = joblib.load('./lr_model.pkl') \n",
    "\n",
    "\n",
    "# SVM\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "# SVM은 원핫인코딩 하지 않음\n",
    "svm_model.fit(x_train, np.argmax(y_train, axis=1))\n",
    "# 모형 저장\n",
    "joblib.dump(svm_model, './svm_model.pkl')\n",
    "svm_model = joblib.load('./svm_model.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - 딥러닝\n",
    "- 이미지인식에 특화된 딥러닝 모델(CNN) 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 6, 6, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 6, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 300)               345900    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 635,342\n",
      "Trainable params: 635,342\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D , Dropout , Flatten , Activation, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# 데이터 불러오기\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# 데이터 전처리\n",
    "train_images = train_images.reshape(train_images.shape[0],train_images.shape[1],train_images.shape[2],1)\n",
    "train_images = train_images/255.0\n",
    "\n",
    "IMAGE_SIZE = 28 # mnist 이미지 사이즈\n",
    "input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "\n",
    "# 모델 구축\n",
    "x = Conv2D(filters=32, kernel_size=(3, 3), padding='valid', activation='relu')(input_tensor)\n",
    "x = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size = (3,3), padding = 'same', activation='relu')(x)\n",
    "x = Conv2D(filters=64, kernel_size = (3,3), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size = 2)(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size = (3,3), padding='same', activation='relu' )(x)\n",
    "x = Conv2D(filters=128, kernel_size = (3,3), padding='same', activation='relu' )(x)\n",
    "x = MaxPooling2D(pool_size = 2)(x)\n",
    "\n",
    "# mnist의 클래스가 10개 이므로 마지막 classification의 Dense layer units갯수는 10\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(300, activation='relu', name='fc1')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(10, activation='softmax', name='output')(x)\n",
    "\n",
    "cnn_model = Model(inputs=input_tensor, outputs=output)\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer는 Adam으로 설정하고, label값이 원-핫 인코딩이 아니므로 loss는 sparse_categorical_crossentropy\n",
    "cnn_model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51000 samples, validate on 9000 samples\n",
      "Epoch 1/10\n",
      "51000/51000 [==============================] - 118s 2ms/sample - loss: 0.4775 - acc: 0.8419 - val_loss: 0.0646 - val_acc: 0.9814\n",
      "Epoch 2/10\n",
      "51000/51000 [==============================] - 111s 2ms/sample - loss: 0.0880 - acc: 0.9724 - val_loss: 0.0471 - val_acc: 0.9857\n",
      "Epoch 3/10\n",
      "51000/51000 [==============================] - 113s 2ms/sample - loss: 0.0584 - acc: 0.9819 - val_loss: 0.0364 - val_acc: 0.9906\n",
      "Epoch 4/10\n",
      "51000/51000 [==============================] - 130s 3ms/sample - loss: 0.0458 - acc: 0.9860 - val_loss: 0.0283 - val_acc: 0.9921\n",
      "Epoch 5/10\n",
      "51000/51000 [==============================] - 112s 2ms/sample - loss: 0.0367 - acc: 0.9888 - val_loss: 0.0289 - val_acc: 0.9916\n",
      "Epoch 6/10\n",
      "51000/51000 [==============================] - 115s 2ms/sample - loss: 0.0315 - acc: 0.9897 - val_loss: 0.0254 - val_acc: 0.9933\n",
      "Epoch 7/10\n",
      "51000/51000 [==============================] - 112s 2ms/sample - loss: 0.0278 - acc: 0.9912 - val_loss: 0.0318 - val_acc: 0.9922\n",
      "Epoch 8/10\n",
      "51000/51000 [==============================] - 115s 2ms/sample - loss: 0.0249 - acc: 0.9918 - val_loss: 0.0247 - val_acc: 0.9933\n",
      "Epoch 9/10\n",
      "51000/51000 [==============================] - 114s 2ms/sample - loss: 0.0213 - acc: 0.9930 - val_loss: 0.0249 - val_acc: 0.9933\n",
      "Epoch 10/10\n",
      "51000/51000 [==============================] - 113s 2ms/sample - loss: 0.0182 - acc: 0.9938 - val_loss: 0.0265 - val_acc: 0.9937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x150a32f28d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 적합 (모델 구축에 의의가 있으므르 epochs는 10으로 설정.)\n",
    "# epochs가 적기 때문에 오버피팅 가능성은 배제(earlystopping이나 learning rate 조정 하지 않음)\n",
    "# val_acc를 확인해보면 감소하지 않기 때문에 오버피팅 되지 않았다고 판단\n",
    "cnn_model.fit(x=train_images, y=train_labels, batch_size=512, epochs=10, validation_split=0.15 ) # validation 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1219 21:38:47.094855 29956 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1219 21:38:47.095882 29956 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "cnn_model.save('./cnn_model')\n",
    "cnn_model = load_model(\"./cnn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 모형 선정\n",
    "- 제일 좋은 성능의 모형 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 제일 좋은 성능의 모형 선택\n",
    "# 성능평가\n",
    "# ML\n",
    "# 성능평가를 위한 테스트 데이터 전처리\n",
    "x_test = x_test/255.0\n",
    "\n",
    "# one-hot encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_test = to_categorical(y_test) # one-hot encoding\n",
    "\n",
    "# x_test flatten\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
    "\n",
    "\n",
    "# DL\n",
    "# 성능평가를 위한 테스트 데이터 전처리\n",
    "test_images = test_images.reshape(test_images.shape[0],test_images.shape[1],test_images.shape[2],1)\n",
    "test_images = test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 파일 불러오기\n",
    "import glob\n",
    "ml_model = glob.glob('./*model.pkl')\n",
    "dl_model = ['./cnn_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['.\\\\kn_model.pkl', '.\\\\lr_model.pkl', '.\\\\rf_model.pkl', '.\\\\svm_model.pkl'],\n",
       " ['./cnn_model'])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 파일 확인\n",
    "ml_model, dl_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 8s 833us/sample - loss: 0.0171 - acc: 0.9946\n"
     ]
    }
   ],
   "source": [
    "# test 데이터 적용 및 정확도 저장\n",
    "from sklearn.metrics import accuracy_score\n",
    "result = pd.DataFrame(index=range(0))\n",
    "\n",
    "# 머신러닝(ML)\n",
    "for model_file_nm in ml_model :\n",
    "    model = joblib.load(model_file_nm) # 모델 불러오기\n",
    "    pred = model.predict(x_test) # 예측\n",
    "    if 'lr' in model_file_nm or 'svm' in model_file_nm :\n",
    "        score = accuracy_score(pred, np.argmax(y_test, axis=1)) # 스코어 산출\n",
    "    else :\n",
    "    \n",
    "        score = accuracy_score(pred, y_test) # 스코어 산출\n",
    "    result = pd.concat([result,pd.DataFrame([[model_file_nm,score]])]) # 결과 저장\n",
    "    \n",
    "# 딥러닝(DL)\n",
    "for model_file_nm in dl_model :\n",
    "    model = load_model(model_file_nm) # 모델 불러오기\n",
    "    score = model.evaluate(test_images, test_labels)[1] # 스코어 산출\n",
    "    result =  pd.concat([result,pd.DataFrame([[model_file_nm,score]])]) # 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./cnn_model</td>\n",
       "      <td>0.9946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.\\svm_model.pkl</td>\n",
       "      <td>0.9792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.\\kn_model.pkl</td>\n",
       "      <td>0.9660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.\\lr_model.pkl</td>\n",
       "      <td>0.9258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.\\rf_model.pkl</td>\n",
       "      <td>0.9007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model  accuracy_score\n",
       "0      ./cnn_model          0.9946\n",
       "1  .\\svm_model.pkl          0.9792\n",
       "2   .\\kn_model.pkl          0.9660\n",
       "3   .\\lr_model.pkl          0.9258\n",
       "4   .\\rf_model.pkl          0.9007"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 확인 및 accuracy_score로 정렬\n",
    "result.columns = ['model', 'accuracy_score']\n",
    "result.sort_values('accuracy_score', ascending=False).reset_index(drop=True)\n",
    "# 딥러닝 모델이 가장 좋은 정확도를 보였고 머신러닝 중에서는 SVM이 가장 좋은 정확도를 보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 참고\n",
    "# 머신러닝을 활용한 이미지 인식의 경우 이미지 데이터의 픽셀값들이 아닌 이미지의 특성(가령 사람 이미지라면 눈의 크기, 코의 크기, 눈과 눈 사이 거리 등 사람을 특정 지을 수 있는 속성)을 활용하는 것으로 알고 있음\n",
    "# 본 프로젝트는 강의록을 참고해 진행했으므로 28X28 데이터를 784 array로 바꾸어 머신러닝 기법을 적용해보았음\n",
    "# 또한 mnist 데이터는 숫자가 전체 이미지 정가운데 있어 픽셀값들로도 충분히 학습이 가능하다고 생각됨\n",
    "# 추가로 이미지 인식에 특화된 딥러닝 모델에 관해 구글을 통해 학습하고 모델을 구축해봄"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
